{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:52.370775Z",
     "start_time": "2024-03-28T18:21:52.368407Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio de regresión\n",
    "\n",
    "Se quiere determinar la relación entre la concentración de cierto fármaco en el torrente sanguíneo y el tiempo transcurrido desde que se administró el fármaco. Se recopila datos sobre la concentración de la droga en el torrente sanguíneo en diferentes intervalos de tiempo después de la administración."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:52.477713Z",
     "start_time": "2024-03-28T18:21:52.467770Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/drug.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/drug.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# cargando los datos desde un csv\u001b[39;00m\n\u001b[0;32m      2\u001b[0m dataset\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/drug.csv'"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"datasets/drug.csv\") # cargando los datos desde un csv\n",
    "dataset.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:52.522113Z",
     "start_time": "2024-03-28T18:21:52.515313Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:52.727927Z",
     "start_time": "2024-03-28T18:21:52.558644Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pandas nos da algunas herramientas de graficado\n",
    "plt.figure(figsize=(7, 5))\n",
    "#dataset.Time.hist()\n",
    "dataset[\"Time\"].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:52.862585Z",
     "start_time": "2024-03-28T18:21:52.732387Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "dataset.Concentration.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:52.953273Z",
     "start_time": "2024-03-28T18:21:52.864680Z"
    }
   },
   "outputs": [],
   "source": [
    "# podemos ver cuál es la relación entre ambas variables....\n",
    "plt.figure(figsize=(7, 5))\n",
    "correlacion_drug = np.corrcoef(dataset[\"Time\"], dataset[\"Concentration\"])\n",
    "sns.heatmap(data=correlacion_drug, annot=True, annot_kws={\"size\": 16})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:53.100485Z",
     "start_time": "2024-03-28T18:21:52.955871Z"
    }
   },
   "outputs": [],
   "source": [
    "# Graficamos el dataset\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(dataset['Time'], dataset['Concentration'] , color='r', marker=\"x\", s=60)\n",
    "plt.grid(True, linewidth=0.5)\n",
    "plt.xlabel('Tiempo [h]', fontsize=14)\n",
    "plt.ylabel('Concentración [mg/L]', fontsize=14)\n",
    "plt.tick_params(axis='x', labelsize=12)\n",
    "plt.tick_params(axis='y', labelsize=12)\n",
    "plt.title('Dataset de concentración de droga vs. tiempo', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos los datos y de hecho vemos que hay una relación lineal entre las dos variables, por lo tanto, asumimos que es podemos usar **regresion lineal simple** (ya que hay una variable independiente y otra dependiente) para poder resolver nuestro problema.\n",
    "\n",
    "Ahora vamos a armar nuestro modelo, para ello vamos a utilizar el proceso que vimos de Machine Learning\n",
    "\n",
    "![proceso ML](./img/proceso_ml.png)\n",
    "\n",
    "Es decir, necesitaremos datos de entrenamiento y datos de test. Esto se puede hacer facilmente con la libreria **scikit-learn** que nos permite separar nuestros datos para entrenar y para testear el funcionamiento de nuestro modelo.\n",
    "\n",
    "Puedes también visitar la pagina de scikit-learn [Aca](https://scikit-learn.org/stable/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:53.210995Z",
     "start_time": "2024-03-28T18:21:53.104382Z"
    }
   },
   "outputs": [],
   "source": [
    "# importando módulo para separar datos de entrenamiento y testeo de scikit-learn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:53.226778Z",
     "start_time": "2024-03-28T18:21:53.224163Z"
    }
   },
   "outputs": [],
   "source": [
    "# Armamos un DataFrame con los features\n",
    "X = dataset[[\"Time\"]]\n",
    "# Y con la variable dependiente (target)\n",
    "y = dataset[\"Concentration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:53.279933Z",
     "start_time": "2024-03-28T18:21:53.274111Z"
    }
   },
   "outputs": [],
   "source": [
    "# valores de X\n",
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:53.368194Z",
     "start_time": "2024-03-28T18:21:53.365317Z"
    }
   },
   "outputs": [],
   "source": [
    "# valores de y\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:53.397856Z",
     "start_time": "2024-03-28T18:21:53.395801Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cantidad de elementos en X y en y\n",
    "print(\"Cantidad de elementos en 'X':\", X.shape)\n",
    "print(\"Cantidad de elementos en 'y':\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos el dataset de entrenamiento y testeo. Para este problema usamos el tamaño del test de 30% aprox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:53.448751Z",
     "start_time": "2024-03-28T18:21:53.446378Z"
    }
   },
   "outputs": [],
   "source": [
    "# Separando nuestro dataset en entrenamiento y testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:53.483607Z",
     "start_time": "2024-03-28T18:21:53.481680Z"
    }
   },
   "outputs": [],
   "source": [
    "# Datos de train y de test\n",
    "print(\"Valores de X_train:\",X_train.size)\n",
    "print(\"Valores de y_train:\",y_train.size)\n",
    "print(\"Valores de X_test:\",len(X_test))\n",
    "print(\"Valores de y_test:\",len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para aplicar el modelo de regresión lineal, la forma de implementarlo usando **scikit-learn**, parámetros y formas de uso la podemos encontrar [aca](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:53.609637Z",
     "start_time": "2024-03-28T18:21:53.567673Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creando el modelo de regresión lineal simple:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regresion = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:53.614276Z",
     "start_time": "2024-03-28T18:21:53.610498Z"
    }
   },
   "outputs": [],
   "source": [
    "# Y lo entrenamos, con el set de entrenamiento\n",
    "regresion.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:53.637283Z",
     "start_time": "2024-03-28T18:21:53.635040Z"
    }
   },
   "outputs": [],
   "source": [
    "# Una vez entrenado, podemos ver diferente información del modelo:\n",
    "print(f\"El valor de la intersección de la recta sera {regresion.intercept_ }\")\n",
    "print(f\"El valor del coeficiente de la recta sera {regresion.coef_ }\")\n",
    "print(f\"La ecuación de la recta entonces sera la siguiente: y = {regresion.intercept_ }+({regresion.coef_[0]})X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:53.692813Z",
     "start_time": "2024-03-28T18:21:53.690051Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"El coeficiente de Pearson es {regresion.score(X_train, y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:53.787617Z",
     "start_time": "2024-03-28T18:21:53.784367Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculamos el desvío estándar del modelo\n",
    "std_dev_model = np.sqrt((np.sum((y_train - regresion.predict(X_train))**2))/(y_train.size - 2))\n",
    "print(f\"Desvío estándar del modelo {std_dev_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:53.947678Z",
     "start_time": "2024-03-28T18:21:53.839927Z"
    }
   },
   "outputs": [],
   "source": [
    "# Y si lo graficamos? Graficar siempre nos dara una mejor idea de lo que sucede\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.title('Concentración de droga vs. tiempo', fontsize=16)\n",
    "plt.xlabel('Tiempo [h]', fontsize=14)\n",
    "plt.ylabel('Concentración [mg/L]', fontsize=14)\n",
    "plt.tick_params(axis='x', labelsize=12)\n",
    "plt.tick_params(axis='y', labelsize=12)\n",
    "\n",
    "plt.scatter(X_train, y_train, color='r', marker=\"o\", s=60)\n",
    "plt.plot(X_train, regresion.predict(X_train), color=\"b\", linewidth=2)\n",
    "\n",
    "plt.ylim(0)  # Establece el límite inferior del eje y en cero\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:54.106136Z",
     "start_time": "2024-03-28T18:21:53.950255Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convertir X_train en un vector unidimensional\n",
    "X_train = X_train.to_numpy().flatten()\n",
    "\n",
    "# Regresión lineal usando Numpy\n",
    "regression = np.polyfit(X_train, y_train, 1)\n",
    "regression_line = np.polyval(regression, X_train)\n",
    "\n",
    "# Calcular las distancias entre los puntos y la línea de regresión\n",
    "distances = np.abs(regression_line - y_train)\n",
    "\n",
    "# Graficar los puntos\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.scatter(X_train, y_train, color='r', s=20)\n",
    "\n",
    "# Graficar la línea de regresión\n",
    "plt.plot(X_train, regression_line, color='b', linewidth=2)\n",
    "\n",
    "# Graficar las líneas perpendiculares desde cada punto a la línea de regresión\n",
    "for x, y, distance in zip(X_train, y_train, distances):\n",
    "    plt.plot([x, x], [y, regression[0]*x + regression[1]], color='black', linestyle='-')\n",
    "    plt.text(x, y, f'{distance:.0f}', ha='left', va=\"baseline\", fontsize=16)\n",
    "\n",
    "# Configuraciones adicionales\n",
    "plt.title(\"Distancia entre la línea de regresión y los puntos\", fontsize=16)\n",
    "plt.xlabel('Tiempo [h]', fontsize=14)\n",
    "plt.ylabel('Concentración [mg/L]', fontsize=14)\n",
    "plt.tick_params(axis='x', labelsize=12)\n",
    "plt.tick_params(axis='y', labelsize=12)\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Metricas\n",
    "\n",
    "Entrenamos el modelo, pero para validar si está bien entrenado, debemos usar el dataset de testeo. \n",
    "\n",
    "Vamos a aplicar las siguientes métricas de evaluación usando scikit-learn:\n",
    "- R2\n",
    "- MAE\n",
    "- MSE\n",
    "- RMSE\n",
    "- MAPE\n",
    "- MPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:54.111766Z",
     "start_time": "2024-03-28T18:21:54.108927Z"
    }
   },
   "outputs": [],
   "source": [
    "#Primero obtenemos las predicciones del modelo\n",
    "y_pred = regresion.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:54.115263Z",
     "start_time": "2024-03-28T18:21:54.112882Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:54.149037Z",
     "start_time": "2024-03-28T18:21:54.146549Z"
    }
   },
   "outputs": [],
   "source": [
    "#scikit-learn no tiene el error porcentual medio (MPE) lo vamos a crear nosotros\n",
    "def mean_porcentual_error(yreal, ypred):\n",
    "\n",
    "    return np.mean((yreal-ypred)/yreal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:54.187737Z",
     "start_time": "2024-03-28T18:21:54.183966Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "mpe = mean_porcentual_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:54.302959Z",
     "start_time": "2024-03-28T18:21:54.300171Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"R-cuadrado en test:\", r2)\n",
    "print(\"Error absoluto medio:\", mae)\n",
    "print(\"Error cuadratico medio:\", mse)\n",
    "print(\"Raiz de error cuadratico medio:\", rmse)\n",
    "print(f\"Error absoluto porcentual medio: {mape*100:.2f}%\")\n",
    "print(f\"Error porcentual medio: {mpe*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas no son las únicas métricas que se pueden calcular. Scikit-learn documenta varias [métricas de regresión](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)\n",
    "\n",
    "Una vez que tenemos el modelo, y estamos conforme, podemos guardarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:54.358215Z",
     "start_time": "2024-03-28T18:21:54.351510Z"
    }
   },
   "outputs": [],
   "source": [
    "# Podemos utilizar pickle, existen otras herramientas, pero con esto bastará.\n",
    "import pickle\n",
    "\n",
    "with open('modelo_regresion_lineal.pkl', 'wb') as archivo:\n",
    "    pickle.dump(regresion, archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:54.406232Z",
     "start_time": "2024-03-28T18:21:54.403956Z"
    }
   },
   "outputs": [],
   "source": [
    "#Podemos llamarlo para usarlo con otros valores y predecir según lo que nosotros queremos.\n",
    "with open('modelo_regresion_lineal.pkl', 'rb') as archivo:\n",
    "    modelo_cargado = pickle.load(archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:54.436750Z",
     "start_time": "2024-03-28T18:21:54.432658Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pasándole nuevos datos a por predecir... ¡Ojo con la forma de pasarlos!\n",
    "X_pred = np.array([ [1], [3.5] ]) # Quiero predecir valores para 1 y 3 horas y media\n",
    "\n",
    "predicciones = modelo_cargado.predict(X_pred) \n",
    "predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Regresión lineal multiple\n",
    "\n",
    "Aunque se usó un ejemplo de una regresión lineal simple, todo lo que vimos sirve exactamente para un problema n-dimensional.\n",
    "\n",
    "Este dataset proviene de [acá](https://www.kaggle.com/datasets/farhanmd29/50-startups). Este conjunto de datos tiene datos recopilados de Nueva York, California y Florida sobre 50 empresas emergentes. Las variables utilizadas en el conjunto de datos son ganancias, gasto en I+D, gasto administrativo y gasto en marketing. \n",
    "\n",
    "Queremos predecir la ganancia usando las otras variables. Pero tenemos un problema inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:54.472793Z",
     "start_time": "2024-03-28T18:21:54.466897Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"datasets/50_Startups.csv\") \n",
    "dataset.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:54.508008Z",
     "start_time": "2024-03-28T18:21:54.502974Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que *State* es una variable categorica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:54.552694Z",
     "start_time": "2024-03-28T18:21:54.550462Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"State\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:54.593675Z",
     "start_time": "2024-03-28T18:21:54.591172Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"State\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:54.653789Z",
     "start_time": "2024-03-28T18:21:54.650988Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"State\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hacemos para introducir una variable categórica en un modelo matemático? Usando variables Dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:54.669992Z",
     "start_time": "2024-03-28T18:21:54.667417Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_with_dummies = pd.get_dummies(data=dataset, columns=['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:54.689271Z",
     "start_time": "2024-03-28T18:21:54.685064Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_with_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:54.745933Z",
     "start_time": "2024-03-28T18:21:54.740895Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convertimos en floats\n",
    "dataset_with_dummies = dataset_with_dummies.astype('float')\n",
    "dataset_with_dummies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto lo pueden hacer también con scikit-learn usando LabelEncoder, OneHotEncoder, make_column_transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:54.778970Z",
     "start_time": "2024-03-28T18:21:54.776480Z"
    }
   },
   "outputs": [],
   "source": [
    "#Quitamos una columna de las variables dummy\n",
    "dataset_with_dummies = pd.get_dummies(data=dataset, columns=['State'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:54.851506Z",
     "start_time": "2024-03-28T18:21:54.847151Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_with_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:55.047943Z",
     "start_time": "2024-03-28T18:21:54.962411Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "dataset[\"Profit\"].hist(bins=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:55.186515Z",
     "start_time": "2024-03-28T18:21:55.085394Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "dataset[\"R&D Spend\"].hist(bins=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:55.353010Z",
     "start_time": "2024-03-28T18:21:55.208142Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))\n",
    "dataset[\"Administration\"].hist(bins=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:55.545886Z",
     "start_time": "2024-03-28T18:21:55.368988Z"
    }
   },
   "outputs": [],
   "source": [
    "# Podemos ver cuál es la relación entre variables, recordemos, es mejor con la variable objetivo, pero malo si es entre variables de entrada....\n",
    "plt.figure(figsize=(7, 5))\n",
    "correlacion_profit = dataset_with_dummies.corr().round(2)\n",
    "sns.heatmap(data=correlacion_profit, annot=True, annot_kws={\"size\": 14})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.454314Z",
     "start_time": "2024-03-28T18:21:55.587090Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(data=dataset_with_dummies, diag_kind=\"kde\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porque tengo muchas variables no significa que debo aplicarla al modelo sin ningún criterio. Como vemos, hay variables que están correlacionadas que nos pueden dar problemas.\n",
    "\n",
    "Recordemos la maxima: *Garbage in -> garbage out*.\n",
    "\n",
    "Además, muchas variables es problema a futuro. Nos puede dificultar los pipelines y hacer más difícil de entender los datos.\n",
    "\n",
    "### Apliquemos la regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.458990Z",
     "start_time": "2024-03-28T18:21:59.455916Z"
    }
   },
   "outputs": [],
   "source": [
    "# Armamos un DataFrame con los features\n",
    "X = dataset_with_dummies.drop(columns='Profit')\n",
    "# Y con la variable dependiente (target)\n",
    "y = dataset_with_dummies[\"Profit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.463152Z",
     "start_time": "2024-03-28T18:21:59.459907Z"
    }
   },
   "outputs": [],
   "source": [
    "# Separando nuestro dataset en entrenamiento y testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Datos de train y de test\n",
    "print(\"Dimension de X_train:\",X_train.shape)\n",
    "print(\"Valores de y_train:\",y_train.size)\n",
    "print(\"Dimension de X_test:\",X_test.shape)\n",
    "print(\"Valores de y_test:\",len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Los valores de los atributos numéricos son de similar escala, pero las variables dummies están a muy diferente escala, apliquemos un método de [estandarización](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.465680Z",
     "start_time": "2024-03-28T18:21:59.464231Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.469342Z",
     "start_time": "2024-03-28T18:21:59.466299Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "sc_X = StandardScaler()\n",
    "\n",
    "X_train_scaled = sc_X.fit_transform(X_train)\n",
    "\n",
    "print(f\"Las medias del escalador es {sc_X.mean_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.472895Z",
     "start_time": "2024-03-28T18:21:59.469979Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Los desvío estándar del escalador es {np.sqrt(sc_X.var_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.476610Z",
     "start_time": "2024-03-28T18:21:59.473989Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Escalemos el set de testeo\n",
    "X_test_scaled = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.481599Z",
     "start_time": "2024-03-28T18:21:59.477612Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# StandardScaler transforma el DataFrame en un array de Numpy\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.487398Z",
     "start_time": "2024-03-28T18:21:59.482209Z"
    }
   },
   "outputs": [],
   "source": [
    "regresion = LinearRegression()\n",
    "\n",
    "regresion.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"El valor de la interseccion de la recta sera {regresion.intercept_ }\")\n",
    "print(f\"Los valores de los coeficientes de la recta sera {regresion.coef_ }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.494124Z",
     "start_time": "2024-03-28T18:21:59.491102Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"El coeficiente de Pearson es {regresion.score(X_train_scaled, y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.497100Z",
     "start_time": "2024-03-28T18:21:59.494667Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculamos el desvío estándar del modelo\n",
    "std_dev_model = np.sqrt((np.sum((y_train - regresion.predict(X_train_scaled))**2))/(y_train.size-6))\n",
    "print(f\"Desvío estándar del modelo {std_dev_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "El desvío estándar es con respecto a la escala del target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.500452Z",
     "start_time": "2024-03-28T18:21:59.498111Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Desvío estándar del label {np.std(y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.503499Z",
     "start_time": "2024-03-28T18:21:59.501624Z"
    }
   },
   "outputs": [],
   "source": [
    "#Otenemos las predicciones del modelo\n",
    "y_pred = regresion.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.507428Z",
     "start_time": "2024-03-28T18:21:59.504075Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "mpe = mean_porcentual_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.509831Z",
     "start_time": "2024-03-28T18:21:59.508053Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"R-cuadrado en test:\", r2)\n",
    "print(\"Error absoluto medio:\", mae)\n",
    "print(\"Error cuadratico medio:\", mse)\n",
    "print(\"Raiz de error cuadratico medio:\", rmse)\n",
    "print(f\"Error absoluto porcentual medio: {mape*100:.2f}%\")\n",
    "print(f\"Error porcentual medio: {mpe*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Selección de modelo\n",
    "\n",
    "Para seleccionar el modelo, vamos a usar una técnica de eliminación hacia atrás y usando el criterio de información de Aikake (AIC) y criterio de información bayesiano (BIC). Como scikit-learn no nos da esas métricas para calcular, armamos una función que incorpora esto (esta función solo es válida para regresiones lineales).\n",
    "\n",
    "Otra herramienta para hacer selección de modelos es utilizar una libreria especializada en herramientas estadísticas, llamada [statsmodels](https://www.statsmodels.org/stable/index.html) que automáticamente realiza la bondad de ajuste, junto al cálculo de diferentes métricas, que nos puede ayudar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.512475Z",
     "start_time": "2024-03-28T18:21:59.510340Z"
    }
   },
   "outputs": [],
   "source": [
    "def criterion(X, y, y_pred):\n",
    "    # Agregamos uno porque hay que incorporar a la ordenada al origen\n",
    "    d = X.shape[1]+1\n",
    "    N = X.shape[0]\n",
    "\n",
    "    # Calculamos los residuos al cuadrado\n",
    "    residuals = y - y_pred\n",
    "    Se = np.sum(residuals**2)\n",
    "    # Se/N es la estimación de la varianza si los residuos provienen\n",
    "    # de una normal con media cero.\n",
    "\n",
    "    # Calculamos la estimación del logaritmo de maxima similitud de la regresión lineal\n",
    "    log_lik = np.log(2*np.pi) + np.log(Se/N) + 1\n",
    "    log_lik *= -N/2\n",
    "\n",
    "    #Calculamos ambos criterios\n",
    "    aic = 2*d - 2*log_lik \n",
    "    bic = d*np.log(N) - 2*log_lik\n",
    "   \n",
    "    return aic, bic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Armamos el dataset para entrenar los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.514536Z",
     "start_time": "2024-03-28T18:21:59.513010Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Recuperamos las columnas en X_train_scaled y X_test_scaled\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.519519Z",
     "start_time": "2024-03-28T18:21:59.515203Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columnas de los arrays `X`, `X_train_scaled`, `X_test_scaled` son:\n",
    "- 0: `'R&D Spend'`\n",
    "- 1: `'Administration'`\n",
    "- 2: `'Marketing Spend'`\n",
    "- 3: `'State_Florida'`\n",
    "- 4: `'State_New_York'`\n",
    "\n",
    "Por lo que seleccionaremos los atributos en función de estos números. \n",
    "\n",
    "Armamos el modelo con todos los atributos y calculamos los criterios, para esto usamos siempre el set de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.523629Z",
     "start_time": "2024-03-28T18:21:59.520135Z"
    }
   },
   "outputs": [],
   "source": [
    "regresion = LinearRegression()\n",
    "regresion.fit(X_train_scaled, y_train)\n",
    "y_pred = regresion.predict(X_train_scaled)\n",
    "\n",
    "aic, bic = criterion(X_train_scaled, y_train, y_pred)\n",
    "\n",
    "print(f\"AIC inicial es {np.round(aic)}\")\n",
    "print(f\"BIC inicial es {np.round(bic)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora creaos una función que dado una selección de columnas, entrena un modelo y obtiene AIC y BIC, esto nos va a facilitar ir avanzando paso a paso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.526123Z",
     "start_time": "2024-03-28T18:21:59.524341Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_reg_model(X, y, columns):\n",
    "\n",
    "    # Quitamos las columnas\n",
    "    X_clear = X.loc[:, columns].copy()\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_clear, y)\n",
    "    y_pred = model.predict(X_clear)\n",
    "\n",
    "    return criterion(X_clear, y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora creamos 5 modelos distintos, quitando para cada caso un atributo, y vemos el resultado de AIC y BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.534931Z",
     "start_time": "2024-03-28T18:21:59.526575Z"
    }
   },
   "outputs": [],
   "source": [
    "aic, bic = train_reg_model(X_train_scaled, y_train, ['Administration', 'Marketing Spend', \n",
    "                                                     'State_Florida', 'State_New York'])\n",
    "\n",
    "print(f\"Sacamos a {X_train_scaled.columns[0]}, el modelo nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "print(f\"BIC {np.round(bic, 1)}\")\n",
    "\n",
    "aic, bic = train_reg_model(X_train_scaled, y_train, ['R&D Spend', 'Marketing Spend', \n",
    "                                                     'State_Florida', 'State_New York'])\n",
    "\n",
    "print(f\"Sacamos a {X_train_scaled.columns[1]}, el modelo nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "print(f\"BIC {np.round(bic, 1)}\")\n",
    "\n",
    "aic, bic = train_reg_model(X_train_scaled, y_train, ['R&D Spend', 'Administration', \n",
    "                                                     'State_Florida', 'State_New York'])\n",
    "\n",
    "print(f\"Sacamos a {X_train_scaled.columns[2]}, el modelo nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "print(f\"BIC {np.round(bic, 1)}\")\n",
    "\n",
    "aic, bic = train_reg_model(X_train_scaled, y_train, ['R&D Spend', 'Administration', 'Marketing Spend', \n",
    "                                                     'State_New York'])\n",
    "\n",
    "print(f\"Sacamos a {X_train_scaled.columns[3]}, el modelo nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "print(f\"BIC {np.round(bic, 1)}\")\n",
    "\n",
    "aic, bic = train_reg_model(X_train_scaled, y_train, ['R&D Spend', 'Administration', 'Marketing Spend', \n",
    "                                                     'State_Florida'])\n",
    "\n",
    "print(f\"Sacamos a {X_train_scaled.columns[4]}, el modelo nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "print(f\"BIC {np.round(bic, 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que quitando `'State_Florida'` el modelo mejora más (tanto viendo AIC como BIC, recordar menor es mejor). Pasa de 749 a 746.9. Seguimos quitando columnas y viendo cuanto mejora el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.543571Z",
     "start_time": "2024-03-28T18:21:59.535443Z"
    }
   },
   "outputs": [],
   "source": [
    "aic, bic = train_reg_model(X_train_scaled, y_train, ['Administration', 'Marketing Spend', 'State_New York'])\n",
    "\n",
    "print(f\"Sacamos a {X_train_scaled.columns[0]}, el modelo nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "print(f\"BIC {np.round(bic, 1)}\")\n",
    "\n",
    "aic, bic = train_reg_model(X_train_scaled, y_train, ['R&D Spend', 'Marketing Spend', 'State_New York'])\n",
    "\n",
    "print(f\"Sacamos a {X_train_scaled.columns[1]}, el modelo nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "print(f\"BIC {np.round(bic, 1)}\")\n",
    "\n",
    "aic, bic = train_reg_model(X_train_scaled, y_train, ['R&D Spend', 'Administration', 'State_New York'])\n",
    "\n",
    "print(f\"Sacamos a {X_train_scaled.columns[2]}, el modelo nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "print(f\"BIC {np.round(bic, 1)}\")\n",
    "\n",
    "aic, bic = train_reg_model(X_train_scaled, y_train, ['R&D Spend', 'Administration', 'Marketing Spend'])\n",
    "\n",
    "print(f\"Sacamos a {X_train_scaled.columns[4]}, el modelo nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "print(f\"BIC {np.round(bic, 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que quitando `'State_New_York'` el modelo mejora más. Quitemos otra columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.549807Z",
     "start_time": "2024-03-28T18:21:59.544264Z"
    }
   },
   "outputs": [],
   "source": [
    "aic, bic = train_reg_model(X_train_scaled, y_train, ['Administration', 'Marketing Spend'])\n",
    "\n",
    "print(f\"Sacamos a {X_train_scaled.columns[0]}, el modelo nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "print(f\"BIC {np.round(bic, 1)}\")\n",
    "\n",
    "aic, bic = train_reg_model(X_train_scaled, y_train, ['R&D Spend', 'Marketing Spend'])\n",
    "\n",
    "print(f\"Sacamos a {X_train_scaled.columns[1]}, el modelo nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "print(f\"BIC {np.round(bic, 1)}\")\n",
    "\n",
    "aic, bic = train_reg_model(X_train_scaled, y_train, ['R&D Spend', 'Administration'])\n",
    "\n",
    "print(f\"Sacamos a {X_train_scaled.columns[2]}, el modelo nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "print(f\"BIC {np.round(bic, 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que quitando `'Administration'` el modelo mejora más. Quitemos otra columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.555811Z",
     "start_time": "2024-03-28T18:21:59.550474Z"
    }
   },
   "outputs": [],
   "source": [
    "aic, bic = train_reg_model(X_train, y_train, ['Marketing Spend'])\n",
    "\n",
    "print(f\"Sacamos a {X_train_scaled.columns[0]}, el modelo nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "print(f\"BIC {np.round(bic, 1)}\")\n",
    "\n",
    "aic, bic = train_reg_model(X_train, y_train, ['R&D Spend'])\n",
    "\n",
    "print(f\"Sacamos a {X_train_scaled.columns[2]}, el modelo nos da:\")\n",
    "print(f\"AIC {np.round(aic, 1)}\")\n",
    "print(f\"BIC {np.round(bic, 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui notamos que si quitamos:\n",
    "\n",
    "- `'R&D Spend'` AIC = 817.7 > AIC_previo = 745.2\n",
    "- `'Marketing Spend'` AIC = 746.7 > AIC_previo = 745.2\n",
    "\n",
    "Es decir, ningún caso mejora el modelo, por lo que el mejor modelo que encontramos es el que tiene las columnas:\n",
    "\n",
    "`'R&D Spend'` y `'Marketing Spend'`\n",
    "\n",
    "Recordemos que eran la que mejor correlación nos daban."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.559134Z",
     "start_time": "2024-03-28T18:21:59.556876Z"
    }
   },
   "outputs": [],
   "source": [
    "# Armamos un DataFrame con los features\n",
    "X = dataset_with_dummies[[\"R&D Spend\", \"Marketing Spend\"]]\n",
    "# Y con la variable dependientes (target)\n",
    "y = dataset_with_dummies[\"Profit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.565077Z",
     "start_time": "2024-03-28T18:21:59.559824Z"
    }
   },
   "outputs": [],
   "source": [
    "# Separando nuestro dataset en entrenamiento y testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Escalamos los datos\n",
    "sc_X = StandardScaler()\n",
    "X_train_scaled = sc_X.fit_transform(X_train)\n",
    "X_test_scaled = sc_X.fit_transform(X_test)\n",
    "\n",
    "# Datos de train y de test\n",
    "print(\"Dimension de X_train:\",X_train_scaled.shape)\n",
    "print(\"Valores de y_train:\",y_train.size)\n",
    "print(\"Dimension de X_test:\",X_test_scaled.shape)\n",
    "print(\"Valores de y_test:\",len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.569142Z",
     "start_time": "2024-03-28T18:21:59.565738Z"
    }
   },
   "outputs": [],
   "source": [
    "regresion = LinearRegression()\n",
    "\n",
    "regresion.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"El valor de la intersección de la recta sera {regresion.intercept_ }\")\n",
    "print(f\"Los valores de los coeficientes de la recta sera {regresion.coef_ }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.575514Z",
     "start_time": "2024-03-28T18:21:59.573128Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"El coeficiente de Pearson es {regresion.score(X_train_scaled, y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.580760Z",
     "start_time": "2024-03-28T18:21:59.577037Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculamos el desvío estándar del modelo\n",
    "std_dev_model = np.sqrt((np.sum((y_train - regresion.predict(X_train_scaled))**2))/(y_train.size-2))\n",
    "print(f\"Desvío estándar del modelo {std_dev_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.584926Z",
     "start_time": "2024-03-28T18:21:59.581518Z"
    }
   },
   "outputs": [],
   "source": [
    "#Otenemos las predicciones del modelo\n",
    "y_pred = regresion.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.591084Z",
     "start_time": "2024-03-28T18:21:59.587393Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "mpe = mean_porcentual_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.594194Z",
     "start_time": "2024-03-28T18:21:59.591947Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"R-cuadrado en test:\", r2)\n",
    "print(\"Error absoluto medio:\", mae)\n",
    "print(\"Error cuadratico medio:\", mse)\n",
    "print(\"Raiz de error cuadratico medio:\", rmse)\n",
    "print(f\"Error absoluto porcentual medio: {mape*100:.2f}%\")\n",
    "print(f\"Error porcentual medio: {mpe*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo con el dataset de testing mejoró. Es decir, el modelo tiene menos overfitting, es decir generaliza mejor.\n",
    "\n",
    "Menos variable generaliza mejor.\n",
    "\n",
    "----\n",
    "\n",
    "## Regresión Lasso y Ridge\n",
    "\n",
    "Para ver el efecto de las penalizaciones L1 y L2 en la regresión lineal, vamos a ver el dataset de las 50 startups. Ya vimos, cuando hicimos Selección de modelo mediante eliminación hacia atrás, encontramos que con solo dos atributos (`\"R&D Spend\"`, `\"Marketing Spend\"`), obtuvimos un mejor modelo. Veamos cómo nos afecta el hecho de usar estas penalidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.603558Z",
     "start_time": "2024-03-28T18:21:59.594886Z"
    }
   },
   "outputs": [],
   "source": [
    "#Cargamos el dataset y aplicamos las transformaciones que ya vimos previamente.\n",
    "dataset = pd.read_csv(\"datasets/50_Startups.csv\") \n",
    "dataset.head() \n",
    "dataset_with_dummies = pd.get_dummies(data=dataset, columns=['State'], drop_first=True)\n",
    "dataset_with_dummies = dataset_with_dummies.astype('float')\n",
    "\n",
    "dataset_with_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.606701Z",
     "start_time": "2024-03-28T18:21:59.604240Z"
    }
   },
   "outputs": [],
   "source": [
    "# Armamos el DataFrame con los features\n",
    "X = dataset_with_dummies.drop(columns='Profit')\n",
    "# Y con la variable dependiente (target)\n",
    "y = dataset_with_dummies[\"Profit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.612539Z",
     "start_time": "2024-03-28T18:21:59.607553Z"
    }
   },
   "outputs": [],
   "source": [
    "# Separando nuestro dataset en entrenamiento y testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Escalamos los datos\n",
    "sc_X = StandardScaler()\n",
    "X_train_scaled = sc_X.fit_transform(X_train)\n",
    "X_test_scaled = sc_X.fit_transform(X_test)\n",
    "\n",
    "# Datos de train y de test\n",
    "print(\"Dimension de X_train:\",X_train_scaled.shape)\n",
    "print(\"Valores de y_train:\",y_train.size)\n",
    "print(\"Dimension de X_test:\",X_test_scaled.shape)\n",
    "print(\"Valores de y_test:\",len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.618365Z",
     "start_time": "2024-03-28T18:21:59.613163Z"
    }
   },
   "outputs": [],
   "source": [
    "# Primero aplicamos la regresión lineal con todas las variables y el mejor modelo que vimos \n",
    "# eliminación hacia adelante\n",
    "regresion = LinearRegression()\n",
    "reg_stepwise = LinearRegression()\n",
    "\n",
    "# Entrenamos el modelo\n",
    "regresion.fit(X_train_scaled, y_train)\n",
    "reg_stepwise.fit(X_train_scaled[:, [0,2]], y_train)\n",
    "\n",
    "# Realizamos la parte de testeo\n",
    "y_pred = regresion.predict(X_test_scaled)\n",
    "\n",
    "r2_linear = r2_score(y_test, y_pred)\n",
    "mse_linear = mean_squared_error(y_test, y_pred)\n",
    "rmse_linear = np.sqrt(mse_linear)\n",
    "\n",
    "y_pred_stepwise = reg_stepwise.predict(X_test_scaled[:,[0,2]])\n",
    "\n",
    "r2_stepwise = r2_score(y_test, y_pred_stepwise)\n",
    "mse_stepwise = mean_squared_error(y_test, y_pred_stepwise)\n",
    "rmse_stepwise = np.sqrt(mse_stepwise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En sklearn tenemos a las dos regresiones, [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) y [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:21:59.620589Z",
     "start_time": "2024-03-28T18:21:59.619082Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafiquemos los valores de cada coeficiente a medida que aumenta $\\alpha$ para ambas regresiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:22:02.311102Z",
     "start_time": "2024-03-28T18:21:59.621228Z"
    }
   },
   "outputs": [],
   "source": [
    "coeffs_lasso = np.zeros([5000, 5])\n",
    "coeffs_ridge = np.zeros([5000, 5])\n",
    "\n",
    "# Guardamos los coeficientes de la regresión lineal (alpha = 0)\n",
    "coeffs_lasso[0, :] = regresion.coef_.copy()\n",
    "coeffs_ridge[0, :] = regresion.coef_.copy()\n",
    "alpha_array = np.arange(0, 10000, 2)\n",
    "\n",
    "# Calculamos los coeficientes para diferentes valores de lambda\n",
    "for index, alpha in enumerate(alpha_array):\n",
    "\n",
    "    if index == 0:\n",
    "        continue\n",
    "\n",
    "    # Creamos los modelos\n",
    "    lasso_model = Lasso(alpha=alpha)\n",
    "    ridge_model = Ridge(alpha=alpha)\n",
    "\n",
    "    # Los entrenamos\n",
    "    lasso_model.fit(X_train_scaled, y_train)\n",
    "    ridge_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Guardamos los coeficientes de las regresiones\n",
    "    coeffs_lasso[index, :] = lasso_model.coef_.copy()\n",
    "    coeffs_ridge[index, :] = ridge_model.coef_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:22:02.506686Z",
     "start_time": "2024-03-28T18:22:02.311752Z"
    }
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(9, 3.5))\n",
    "\n",
    "for i in range(coeffs_lasso.shape[1]):\n",
    "    ax[0].plot(alpha_array, coeffs_lasso[:, i])\n",
    "\n",
    "    ax[1].plot(alpha_array, coeffs_ridge[:, i], label=X_train.columns[i])\n",
    "\n",
    "ax[1].legend()\n",
    "ax[0].set_xlim([-100, 8000])\n",
    "ax[1].set_xlim([-100, 4000])\n",
    "\n",
    "ax[0].set_ylabel(\"Coefficients\")\n",
    "ax[0].set_xlabel(\"alpha\")\n",
    "ax[1].set_xlabel(\"alpha\")\n",
    "\n",
    "ax[0].set_title(\"Lasso (L1)\")\n",
    "ax[1].set_title(\"Ridge (L2)\")\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos los efectos de las regresiones, donde en la regresión de Ridge tiende a cero todos los coeficientes, mientras que en la de Lasso, los diferentes coeficientes se van haciendo cero, en el mismo orden de cuando hicimos la selección mediante eliminación hacia atrás.\n",
    "\n",
    "Veamos un ejemplo de dos modelos de cada uno. \n",
    "\n",
    "*Nota: Los valores de Lambda son obtenidos con validación cruzada y búsqueda de hiperparámetros que veremos en AMq1.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:22:02.516086Z",
     "start_time": "2024-03-28T18:22:02.508844Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creamos los modelos\n",
    "lasso_model = Lasso(alpha=871.45)\n",
    "ridge_model = Ridge(alpha=1)\n",
    "\n",
    "# Entrenamos los modelos\n",
    "lasso_model.fit(X_train_scaled, y_train)\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Realizamos la parte de testeo\n",
    "y_pred_lasso = lasso_model.predict(X_test_scaled)\n",
    "y_pred_ridge = ridge_model.predict(X_test_scaled)\n",
    "\n",
    "r2_lasso = r2_score(y_test, y_pred_lasso)\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "rmse_lasso = np.sqrt(mse_lasso)\n",
    "\n",
    "r2_ridge = r2_score(y_test, y_pred_ridge)\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "rmse_ridge = np.sqrt(mse_ridge)\n",
    "\n",
    "print(\"Modelo de regresión lineal\")\n",
    "print(\"R-cuadrado en test:\", r2_linear)\n",
    "print(\"Raiz de error cuadratico medio:\", rmse_linear)\n",
    "\n",
    "print(\"\\nModelo de regresión lineal usando eliminación hacia atrás\")\n",
    "print(\"R-cuadrado en test:\", r2_stepwise)\n",
    "print(\"Raiz de error cuadratico medio:\", rmse_stepwise)\n",
    "\n",
    "print(\"\\nLasso\")\n",
    "print(\"R-cuadrado en test:\", r2_lasso)\n",
    "print(\"Raiz de error cuadratico medio:\", rmse_lasso)\n",
    "\n",
    "print(\"\\nRidge\")\n",
    "print(\"R-cuadrado en test:\", r2_ridge)\n",
    "print(\"Raiz de error cuadratico medio:\", rmse_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que la regresión de Lasso nos dio mejor resultado, el cual es parecido al resultado obtenido en la selección de modelo mediante eliminación hacia atrás. Es un poco mejor, pero claramente muestra una mejora con respecto a una regresión lineal de todos los atributos.\n",
    "\n",
    "Veamos el coeficiente del modelo de regresión Lasso, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:22:02.520460Z",
     "start_time": "2024-03-28T18:22:02.516867Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Los coeficientes de la regresión Lasso con lambda=871 son {lasso_model.coef_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que los coeficientes de la ubicación de las startups son cero. Por lo que, este modelo no tiene en cuenta esos dos valores, por lo que se puede usar el modelo sin pasar esos atributos. \n",
    "\n",
    "La regresión Lasso no puede encontrar el mejor modelo de solo usar los dos atributos `\"R&D Spend\"` y `\"Marketing Spend\"` porque la penalización para que la columna `\"Administration\"` sea cero le afecta mucho también a los valores de las columnas `\"R&D Spend\"` y `\"Marketing Spend\"`, y por consiguiente modelos Lasso sin el atributo `\"Administration\"` rinde peor que la regresión lineal que obtuvimos mediante selección de modelo.\n",
    "\n",
    "Por otro lado, la regresión de Ridge no mejora el resultado obtenido. Esto se debe a que el problema que tenemos, la regresión lineal no presenta problemas de error de varianza. Ridge tiene sentido cuando tenemos muchos atributos y pocas observaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-28T18:22:02.524838Z",
     "start_time": "2024-03-28T18:22:02.522935Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
