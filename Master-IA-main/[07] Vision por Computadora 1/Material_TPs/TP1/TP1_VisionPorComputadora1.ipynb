{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 1 Visión Por Computadora 1\n",
    "\n",
    "* Mauro Aguirregaray\n",
    "* Fabricio Denardi\n",
    "\n",
    "**Consideraciones generales**\n",
    "1. Siempre que lo consideramos necesario, realizamos un tipado de las funciones como una explicación detallada.\n",
    "2. Intentamos nomenclar siempre en inglés variables, métodos, clases etc, aunque para un mejor entendimiento los comentarios los hicimos en español.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Implementar el algoritmo de pasaje a coordenadas cromáticas para librarnos de las variaciones de contraste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo las imagenes\n",
    "img_CC_1 = cv.imread('coord_cromaticas/CoordCrom_1.png')\n",
    "img_CC_2 = cv.imread('coord_cromaticas/CoordCrom_2.png')\n",
    "img_CC_3 = cv.imread('coord_cromaticas/CoordCrom_3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir de BGR a RGB\n",
    "img_CC_1 = cv.cvtColor(img_CC_1, cv.COLOR_BGR2RGB)\n",
    "img_CC_2 = cv.cvtColor(img_CC_2, cv.COLOR_BGR2RGB)\n",
    "img_CC_3 = cv.cvtColor(img_CC_3, cv.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las imágenes\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img_CC_1)\n",
    "plt.title('Imagen 1')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(img_CC_2)\n",
    "plt.title('Imagen 2')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(img_CC_3)\n",
    "plt.title('Imagen 3')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dadas las intensidades de los componentes rojo \\( R \\), verde \\( G \\) y azul \\( B \\), las coordenadas cromáticas se pueden calcular como:\n",
    "\n",
    " X = $\\frac{R}{R + G + B}$ \n",
    "\n",
    " Y = $\\frac{G}{R + G + B}$ \n",
    "\n",
    " Z = $\\frac{B}{R + G + B}$ \n",
    "\n",
    "Donde \\( X \\), \\( Y \\) y \\( Z \\) son las coordenadas cromáticas. La suma de \\( X \\), \\( Y \\) y \\( Z \\) siempre será igual a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_CC(image):\n",
    "    # Convertimos a float32 para evitar problemas con la división\n",
    "    image = image.astype(np.float32)\n",
    "\n",
    "    # Calculamos la suma de los canales R, G, B\n",
    "    sum_channels = np.sum(image, axis=2, keepdims=True)  \n",
    "\n",
    "    # Para evitar la división por 0 hardcodeamos un 1 para esa suma y cuando hagamos la conversión a coord cromaticas pasaremos un 0\n",
    "    sum_channels[sum_channels == 0] = 1\n",
    "\n",
    "    # Calcular las coordenadas cromáticas\n",
    "    chromatic_image = image / sum_channels\n",
    "\n",
    "    return chromatic_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos a coordenadas cromáticas\n",
    "img_CC_1_converted = rgb_to_CC(img_CC_1)\n",
    "img_CC_2_converted = rgb_to_CC(img_CC_2)\n",
    "img_CC_3_converted = rgb_to_CC(img_CC_3)\n",
    "\n",
    "# Ploteamos con coordenadas cromáticas\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img_CC_1_converted)\n",
    "plt.title('Imagen 1')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(img_CC_2_converted)\n",
    "plt.title('Imagen 2')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(img_CC_3_converted)\n",
    "plt.title('Imagen 3')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implementar el algoritmo White Patch para librarnos de las diferencias de color de iluminación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero trabajaremos con las imágenes de las manos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo las imagenes\n",
    "img_WP_Hands1 = cv.imread('white_patch/test_blue.png')\n",
    "img_WP_Hands2 = cv.imread('white_patch/test_green.png')\n",
    "img_WP_Hands3 = cv.imread('white_patch/test_red.png')\n",
    "\n",
    "# Convertir de BGR a RGB\n",
    "img_WP_Hands1 = cv.cvtColor(img_WP_Hands1, cv.COLOR_BGR2RGB)\n",
    "img_WP_Hands2 = cv.cvtColor(img_WP_Hands2, cv.COLOR_BGR2RGB)\n",
    "img_WP_Hands3 = cv.cvtColor(img_WP_Hands3, cv.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las imágenes\n",
    "plt.figure(figsize=(5, 15))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.imshow(img_WP_Hands1)\n",
    "plt.title('Imagen blue')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.imshow(img_WP_Hands2)\n",
    "plt.title('Imagen green')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.imshow(img_WP_Hands3)\n",
    "plt.title('Imagen red')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado un canal de color $C$ (donde $C$ puede ser $R$, $G$, o $B$) y su valor máximo $C_{\\text{max}}$, el valor normalizado $C_{\\text{norm}}$ para un píxel es:\n",
    "\n",
    "Para el canal Rojo $R$:\n",
    "\\[ $R_{\\text{norm}} = \\frac{R}{R_{\\text{max}}} \\times 255$ \\]\n",
    "\n",
    "Para el canal Verde $G$:\n",
    "\\[ $G_{\\text{norm}} = \\frac{G}{G_{\\text{max}}} \\times 255$ \\]\n",
    "\n",
    "Para el canal Azul $B$:\n",
    "\\[ $B_{\\text{norm}} = \\frac{B}{B_{\\text{max}}} \\times 255$ \\]\n",
    "\n",
    "Donde $R_{\\text{norm}}$, $G_{\\text{norm}}$ y $B_{\\text{norm}}$ son los valores normalizados para cada canal de color.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def white_patch(image):\n",
    "    # Convertimos a float32 para evitar problemas con la división\n",
    "    image = image.astype(np.float32)\n",
    "\n",
    "    # Buscamos el máximo en cada canal de color\n",
    "    max_r = np.max(image[:, :, 0])\n",
    "    max_g = np.max(image[:, :, 1])\n",
    "    max_b = np.max(image[:, :, 2])\n",
    "\n",
    "    # Normalizamos cada canal por el valor máximo\n",
    "    image[:, :, 0] = image[:, :, 0] / max_r * 255\n",
    "    image[:, :, 1] = image[:, :, 1] / max_g * 255\n",
    "    image[:, :, 2] = image[:, :, 2] / max_b * 255\n",
    "\n",
    "    # Convertir la imagen de vuelta a tipo uint8\n",
    "    image = np.clip(image, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos con WP\n",
    "img_WP_Hands1_converted = white_patch(img_WP_Hands1)\n",
    "img_WP_Hands2_converted = white_patch(img_WP_Hands2)\n",
    "img_WP_Hands3_converted = white_patch(img_WP_Hands3)\n",
    "\n",
    "# Primera columna de imágenes convertidas\n",
    "plt.subplot(3, 2, 1)\n",
    "plt.imshow(img_WP_Hands1_converted)\n",
    "plt.title('Imagen blue (converted)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(3, 2, 3)\n",
    "plt.imshow(img_WP_Hands2_converted)\n",
    "plt.title('Imagen green (converted)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(3, 2, 5)\n",
    "plt.imshow(img_WP_Hands3_converted)\n",
    "plt.title('Imagen red (converted)')\n",
    "plt.axis('off')\n",
    "\n",
    "# Segunda columna de imágenes originales\n",
    "plt.subplot(3, 2, 2)\n",
    "plt.imshow(img_WP_Hands1)\n",
    "plt.title('Imagen blue (original)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(3, 2, 4)\n",
    "plt.imshow(img_WP_Hands2)\n",
    "plt.title('Imagen green (original)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(3, 2, 6)\n",
    "plt.imshow(img_WP_Hands3)\n",
    "plt.title('Imagen red (original)')\n",
    "plt.axis('off')\n",
    "\n",
    "# Mostrar las imágenes\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasamos a ver el alien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargo las imagenes\n",
    "img_WP_Alien1 = cv.imread('white_patch/wp_blue.jpg')\n",
    "img_WP_Alien2 = cv.imread('white_patch/wp_green.png')\n",
    "img_WP_Alien3 = cv.imread('white_patch/wp_green2.jpg')\n",
    "img_WP_Alien4 = cv.imread('white_patch/wp_red.png')\n",
    "img_WP_Alien5 = cv.imread('white_patch/wp_red2.jpg')\n",
    "\n",
    "# Convertir de BGR a RGB\n",
    "img_WP_Alien1 = cv.cvtColor(img_WP_Alien1, cv.COLOR_BGR2RGB)\n",
    "img_WP_Alien2 = cv.cvtColor(img_WP_Alien2, cv.COLOR_BGR2RGB)\n",
    "img_WP_Alien3 = cv.cvtColor(img_WP_Alien3, cv.COLOR_BGR2RGB)\n",
    "img_WP_Alien4 = cv.cvtColor(img_WP_Alien4, cv.COLOR_BGR2RGB)\n",
    "img_WP_Alien5 = cv.cvtColor(img_WP_Alien5, cv.COLOR_BGR2RGB)\n",
    "\n",
    "# Convertimos con WP\n",
    "img_WP_Alien1_converted = white_patch(img_WP_Alien1)\n",
    "img_WP_Alien2_converted = white_patch(img_WP_Alien2)\n",
    "img_WP_Alien3_converted = white_patch(img_WP_Alien3)\n",
    "img_WP_Alien4_converted = white_patch(img_WP_Alien4)\n",
    "img_WP_Alien5_converted = white_patch(img_WP_Alien5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar las imágenes\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Primera fila de imágenes convertidas\n",
    "plt.subplot(2, 5, 1)\n",
    "plt.imshow(img_WP_Alien1_converted)\n",
    "plt.title('Imagen blue (converted)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 5, 2)\n",
    "plt.imshow(img_WP_Alien2_converted)\n",
    "plt.title('Imagen green (converted)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 5, 3)\n",
    "plt.imshow(img_WP_Alien3_converted)\n",
    "plt.title('Imagen green 2 (converted)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 5, 4)\n",
    "plt.imshow(img_WP_Alien4_converted)\n",
    "plt.title('Imagen red (converted)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 5, 5)\n",
    "plt.imshow(img_WP_Alien5_converted)\n",
    "plt.title('Imagen red 2 (converted)')\n",
    "plt.axis('off')\n",
    "\n",
    "# Segundaa fila de imágenes originales\n",
    "# Primera fila de imágenes convertidas\n",
    "plt.subplot(2, 5, 6)\n",
    "plt.imshow(img_WP_Alien1)\n",
    "plt.title('Imagen blue (original)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 5, 7)\n",
    "plt.imshow(img_WP_Alien2)\n",
    "plt.title('Imagen green (original)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 5, 8)\n",
    "plt.imshow(img_WP_Alien3)\n",
    "plt.title('Imagen green 2 (original)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 5, 9)\n",
    "plt.imshow(img_WP_Alien4)\n",
    "plt.title('Imagen red (original)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 5, 10)\n",
    "plt.imshow(img_WP_Alien5)\n",
    "plt.title('Imagen red 2 (original)')\n",
    "plt.axis('off')\n",
    "\n",
    "# Mostrar las imágenes\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Mostrar los resultados obtenidos y analizar las posibles fallas (si es que las hay) en el caso de White patch.\n",
    "\n",
    "Resulta muy interesante analizar como se comporta el white patch en las imágenes convertidas:\n",
    "\n",
    "* En el caso de las imagenes de las manos el comportamiento es excelente, si bien se nota alguna diferencia entre las imágenes, si solo se muestra la imagen ya convertida es muy díficil observar de que imagen precede, es decir, no se puede distinguir con que tipo de luz fue iluminada la foto en un principio. De esta manera cumple a la perfección la premisa de white patch que es que la luz que lo ilumina no influencie en la percepción que tenemos del objeto.\n",
    "* En cuanto a la imagen del alien, se observan más limitaciones del algoritmo y que tampoco puede hacer \"magia\". Si bien en todos los casos la percepción que tenemos del objeto se influencia por la luz que se ilumina, sí encontramos que se llegan percibir algunos colores que en la imagen original es dificil de observar, en dónde más se nota esto es en la imagen green (el verde de la figura se diferencia mucho más que en la original) y en la red (\"aparecen\" los colores verdes de la figura que no se veían claramente antes)\n",
    "\n",
    "En cuanto a las limitaciones matemáticas del algoritmo distinguimos:\n",
    "\n",
    "1. Si el máximo en cada canal es 255 el numerador y denominador se me cancelar y queda igual a la imagen original. Esto es probable que ocurra y haría que esté realizando un gasto computacional sin ningun beneficio.\n",
    "\n",
    "2. Algo que es poco probable que ocurra, pero es un problema en fin, es que el denominador sea 0, lo que significaría que el canal esté totalmente anulado (el máximo de toda la imagen es 0) y sería un problema potencial del input a resolver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Para las imágenes img1_tp.png y img2_tp.png leerlas con OpenCV en escala de grisas y visualizarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar una imagen en modo monocromático (un canal)\n",
    "img1_tp = cv.imread('img1_tp.png', cv.IMREAD_GRAYSCALE)\n",
    "img2_tp = cv.imread('img2_tp.png', cv.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 286.5, 287.5, -0.5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar las imágenes\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img1_tp, cmap='gray')\n",
    "plt.title('Imagen 1')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img2_tp, cmap='gray')\n",
    "plt.title('Imagen 2')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Elija el numero de bins que crea conveniente y grafique su histograma, compare los histogramas entre si.\n",
    "Explicar lo que se observa, si tuviera que entrenar un modelo de clasificación/detección de imágenes,\n",
    "considera que puede ser de utilidad tomar como ‘features’ a los histogramas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Función para generar los histogramas cambiando la cantidad de bins\n",
    "\n",
    "def get_hist (img_to_process:np.ndarray, bins:int=256) -> np.ndarray:\n",
    "    '''\n",
    "    Crea el histograma \n",
    "    '''    \n",
    "    hist,bins_edges = np.histogram(img_to_process.ravel(), bins=bins, range=[0, 256])\n",
    "\n",
    "    # Calcular la posición central de cada barra\n",
    "    bin_centers = (bins_edges[:-1] + bins_edges[1:]) / 2\n",
    "    \n",
    "    # Calcular el ancho de las barras\n",
    "    \n",
    "    width = np.diff(bins_edges)\n",
    "                     \n",
    "\n",
    "    return hist,bins_edges,bin_centers,width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img1_tp.png\n",
      "img2_tp.png\n"
     ]
    }
   ],
   "source": [
    "img_list = ['img1_tp.png','img2_tp.png']\n",
    "bins_test = [8,16,32,64,128,256]\n",
    "for img_name in img_list:\n",
    "    print (img_name)\n",
    "    img = cv.imread(img_name, cv.IMREAD_GRAYSCALE)\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "    for ix,bins in enumerate(bins_test):\n",
    "        hist,bins_edges,bin_centers,_width =get_hist(img,bins)\n",
    "\n",
    "        plt.subplot(3, 2, ix + 1)  # Crear subtrama\n",
    "        plt.bar(bin_centers, hist, width=_width,  align='edge', edgecolor='black')  # Graficar el histograma con barras\n",
    "   \n",
    "        #plt.plot(hist)  # Graficar el histograma\n",
    "        plt.title(f'Hist / Bins {bins}')\n",
    "        plt.xlabel('Intensidad de píxel')\n",
    "        plt.ylabel('Frecuencia')\n",
    "        plt.xlim([bins_edges[0], bins_edges[-1]])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Ambas imagenes, a pesar de ser diferentes en cuanto a lo que muestran (un degreadé vs una margarita) tienen una misma -o muy similar- distribución en sus histogramas\n",
    "\n",
    "2. Los histogramas presentan una distrubición bimodal, aunque hay una saturación de blancos marcada.\n",
    "\n",
    "3. La cantidad de bins adecuada, podrìa ser 32 o 64 así se distingue bien la bimodal y el peso de la sobresaturación de blancos no es tanto.\n",
    "\n",
    "4. Respecto a si pueden ser considerados como un feature, la respuesta es sí, por los siguientes motivos:\n",
    "- Son invariantes a la posición/orientación\n",
    "- Me dan un descriptor compacto, sencillo, representativo y de fácil lectura\n",
    "- Son sencillos de calcular\n",
    "- Puedo obtener una reducción de la dimensionalidad\n",
    "- Vale aclarar que no deberían ser el único feature, dado que, como vemos en este caso, un simple degradé tiene el mismo histograma que una flor, que podría estar siendo en realidad nuestro objeto de análisis. Por otro lado, el degradé nos podría ayudar como una especie de hash o representación de la imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Para la imagen segmentacion.png analice el histograma de los canales RGB. Segmente algunos de los elementos presentes en la imagen (agua, cielo, tierra) y muestre, aplicando mascaras, las regiones en imágenes separadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero analizamos el histograma de los canales RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos la figura\n",
    "img_segmentacion = cv.imread('segmentacion.png')\n",
    "\n",
    "img_segmentacion_RGB = cv.cvtColor(img_segmentacion, cv.COLOR_BGR2RGB)\n",
    "plt.figure()\n",
    "plt.imshow(img_segmentacion_RGB)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = {'r':0,'g':1,'b':2}\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "for k,v in channels.items():\n",
    "    img_channel = img_segmentacion_RGB[:, :, v].flatten()\n",
    "\n",
    "    hist,bins_edges,bin_centers,_width =get_hist(img_channel,bins)\n",
    "\n",
    "    plt.plot(bin_centers, hist, color=k, linewidth=2)\n",
    "\n",
    "    plt.xlabel('Intensidad de píxel')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.xlim([0, 256])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Varias conclusiones podemos sacar solo viendo el histograma por canal:\n",
    "\n",
    "1. La imagen parece tener buen contraste, ya que tenemos una gran cantidad de píxeles en ambos extremos de intensidad\n",
    "2. Además de lo anterior, todos los niveles de intensidad están representados, lo que muestra que la imagen tiene un alto rángo dinámico.\n",
    "3. Hay una clara subexposición por el pico de valores con intensidad 0 o cercana a 0. Esto lo vemos por las sombras de la imagen.\n",
    "4. Por último, en el histograma  se ve una distribución de intensidades suave y continua, no parece ser que la imagen haya sido modificada digitalmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora pasamos a crear las máscaras, la idea es tener tres máscaras para cielo, agua y tierra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26004aca9d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lo pasamos a HSV\n",
    "img_segmentacion_HSV = cv.cvtColor(img_segmentacion, cv.COLOR_BGR2HSV)\n",
    "plt.figure()\n",
    "plt.imshow(img_segmentacion_HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos la función que aplica la máscara para la subregión analizada\n",
    "def get_region(region_name:str, img_HSV:np.ndarray, img_RGB:np.ndarray, region:list, sigma:int=3 ):\n",
    "    print (f\"Nombre de la región: {region_name}\")\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 10))\n",
    "\n",
    "    axs[0].imshow(img_RGB)\n",
    "    axs[0].set_title('Original')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "\n",
    "    x1,x2,y1,y2 = region[0],region[1],region[2],region[3]\n",
    "    img_region = img_RGB[y1:y2,x1:x2,:]\n",
    "    \n",
    "    \n",
    "   \n",
    "    img_muestra_hsv = img_HSV[y1:y2,x1:x2,:]\n",
    "\n",
    "    h, s, v = cv.split(img_muestra_hsv)\n",
    "    color_mean, color_std = cv.meanStdDev(h)\n",
    "    \n",
    "    s_mean, s_std = cv.meanStdDev(s)\n",
    "    v_mean, v_std = cv.meanStdDev(v)\n",
    "\n",
    "\n",
    "    color_l = (int(color_mean[0][0] - sigma[0] * color_std[0][0]),int(s_mean[0][0] - sigma[1] * s_std[0][0]),int(v_mean[0][0]- sigma[2] * v_std[0][0]))\n",
    "    color_u = (int(color_mean[0][0] + sigma[0] * color_std[0][0]),int(s_mean[0][0] + sigma[1] * s_std[0][0]),int(v_mean[0][0] + sigma[2] * v_std[0][0]))\n",
    "\n",
    "    mask = cv.inRange(img_HSV, color_l,  color_u)\n",
    "    img_segmentada = cv.bitwise_and(img_RGB, img_RGB, mask=mask)\n",
    "\n",
    "    axs[1].imshow(img_segmentada)\n",
    "    axs[1].set_title(region_name)\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    axs[2].imshow(img_region)\n",
    "    axs[2].set_title('Región')\n",
    "    axs[2].axis('off')\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imprimir la imagen otra vez para tener la imagen con coordenadas e ir jugando con los x e y\n",
    "plt.figure(figsize=(20, 16))\n",
    "plt.imshow(img_segmentacion_RGB)\n",
    "plt.grid(True)\n",
    "\n",
    "plt.xticks(range(0, img_segmentacion_RGB.shape[1], 25))\n",
    "\n",
    "plt.yticks(range(0, img_segmentacion_RGB.shape[0], 25))\n",
    "\n",
    "# Ajustar los límites de los ejes para que coincidan con la imagen\n",
    "plt.xlim(0, img_segmentacion_RGB.shape[1])\n",
    "plt.ylim(img_segmentacion_RGB.shape[0], 0)  # Invertir el eje y para que el origen (0,0) esté en la esquina superior izquierda\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de la región: Cielo\n",
      "Nombre de la región: Agua\n",
      "Nombre de la región: Tierra\n"
     ]
    }
   ],
   "source": [
    "#Coords ->  X1,x2, Y1, Y2 en Fil - Col\n",
    "#regions = {'Cielo':([0,950,0,275],3),'Agua':([500,600,300,350],2),'Tierra':([400,500,500,600],3)}\n",
    "regions = {'Cielo':([0,50,200,250],[2,15,15]),'Agua':([500,600,300,350],[2,2,3]),'Tierra':([400,500,500,600],[3,3,2])}\n",
    "\n",
    "for region, coords in regions.items():\n",
    "    get_region(region,img_segmentacion_HSV, img_segmentacion_RGB, coords[0],coords[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MASTER_IA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
