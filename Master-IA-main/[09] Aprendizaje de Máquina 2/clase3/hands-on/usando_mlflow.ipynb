{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb5ff88ab0258ddf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T18:10:08.255959Z",
     "start_time": "2024-04-20T18:10:07.050518Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from plots import plot_confusion_matrix, plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e766c21da279c171",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T18:10:08.792263Z",
     "start_time": "2024-04-20T18:10:08.257130Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: AWS_ACCESS_KEY_ID=minio\n",
      "env: AWS_SECRET_ACCESS_KEY=minio123\n",
      "env: MLFLOW_S3_ENDPOINT_URL=http://localhost:9000\n",
      "env: AWS_ENDPOINT_URL_S3=http://localhost:9000\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Para que funcione, todos nuestros scripts debemos exportar las siguientes variables de entorno\n",
    "%env AWS_ACCESS_KEY_ID=minio   \n",
    "%env AWS_SECRET_ACCESS_KEY=minio123 \n",
    "%env MLFLOW_S3_ENDPOINT_URL=http://localhost:9000\n",
    "%env AWS_ENDPOINT_URL_S3=http://localhost:9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d12e83910db1d6e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T18:10:09.156884Z",
     "start_time": "2024-04-20T18:10:08.793349Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minio\n",
      "minio123\n",
      "http://localhost:9000\n"
     ]
    }
   ],
   "source": [
    "!echo $AWS_ACCESS_KEY_ID\n",
    "!echo $AWS_SECRET_ACCESS_KEY\n",
    "!echo $MLFLOW_S3_ENDPOINT_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaf335d5d202a7c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# MLFlow\n",
    "\n",
    "Como hemos explorado en clase, MLFlow es una herramienta de código abierto diseñada para gestionar de manera eficiente el ciclo de vida completo de los modelos de Machine Learning. Este \n",
    "conjunto de funcionalidades incluye varios aspectos fundamentales:\n",
    "\n",
    "- **Tracking**: Registra de forma sistemática los resultados y parámetros de los modelos durante su entrenamiento, permitiendo una comparación fácil y una comprensión más profunda de \n",
    "su rendimiento.\n",
    "- **Projects**: Empaqueta el código de manera que sea completamente reproducible, facilitando la colaboración entre equipos y garantizando la portabilidad del código en diferentes entornos.\n",
    "- **Models**: Proporciona herramientas para gestionar el versionado de los modelos, así como para desplegar modelos de ML como endpoints de servicio. Esta capacidad es especialmente \n",
    "valiosa, ya que MLFlow ofrece integraciones para el despliegue de modelos en la nube. Además, permite la exportación de modelos compatibles con Apache Spark.\n",
    "\n",
    "## Instalación de MLFlow\n",
    "\n",
    "Para este hands-on, utilizaremos Docker para configurar un entorno de MLFlow que nos permitirá acceder a todas las funcionalidades necesarias. Utilizaremos Docker Compose para orquestar \n",
    "no solo el servicio de MLFlow, sino también una base de datos PostgreSQL y buckets S3 utilizando MinIO. MLFlow utiliza tanto la base de datos como el bucket para almacenar \n",
    "información relevante sobre los modelos.\n",
    "\n",
    "Para comenzar con este hands-on, ejecutamos el siguiente comando para levantar los servicios:\n",
    "\n",
    "```Bash\n",
    "docker-compose up \n",
    "```\n",
    "\n",
    "Este comando garantizará que todos los servicios necesarios estén disponibles y listos para su uso en nuestro entorno de desarrollo de MLFlow.\n",
    "\n",
    "## MLFlow Tracking\n",
    "\n",
    "### Conceptos importantes sobre MLFlow Tracking\n",
    "\n",
    "Guardar el tracking de nuestros modelos en nuestro servidor de MLflow es muy sencillo. Simplemente hay que hacer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18084b3d2f776d6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T18:10:09.634233Z",
     "start_time": "2024-04-20T18:10:09.631834Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('http://localhost:5001')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94fbffd61a15d81",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Con esto, ya tendremos hecha la conexión con nuestro servidor de MLFlow\n",
    "\n",
    "Opcionalmente, podemos crear un experimento donde incluir los parámetros, si es que no lo tenemos ya. Cada proyecto diferente debería tener su propio experimento. Para ello, usaremos el \n",
    "método `create_experiment`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20084ee800ef6511",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T18:10:11.189369Z",
     "start_time": "2024-04-20T18:10:11.101699Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "experiment_name = \"experiment_number_9\"\n",
    "\n",
    "if not mlflow.get_experiment_by_name(experiment_name):\n",
    "    mlflow.create_experiment(name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aa3ef357c4e67e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Existe los siguientes datos que podemos incluir en MLflow:\n",
    "\n",
    "- **Parámetros del modelo**: Indica parámetros del modelo utilizado. Se registran usando el método `log_param`.\n",
    "- **Métricas**: Se refiere a métricas de rendimiento, tales como el RMSE, accuracy, AUC, etc. Se registran usando el método `log_metric`.\n",
    "- **Artefactos**: permite incluir archivos. El uso típico es incluir datos de entrenamiento, imágenes del entrenamiento, etc. Los artefactos se registran usando el método `log_artifact`.\n",
    "- **Modelos**: permite incluir modelos. Los modelos se registran usando el método `log_model`. Además, MLFlow cuenta con tecnicas de auto-registro para las librerías Scikit-Learn, TensorFlow, \n",
    "Gluon, XGBoost, LightGBM, Statsmodels. Es decir, que se puede usar el método `autolog` y MLFlow automáticamente registrará los datos que vayamos generando. \n",
    "\n",
    "Para poder registrar, antes debemos indicar a MLFlow que *escuche*. Esto se puede hacer de dos formas:\n",
    "\n",
    "1. Usar el método `star_run` junto con with para evitar cerrar el proceso.\n",
    "```Python\n",
    "with mlflow.start_run():\n",
    "   mlflow.log_param('max_depth', max_depth)\n",
    "```\n",
    "\n",
    "2. Usar el método `start_run` y `end_run`\n",
    "```Python\n",
    "mlflow.start_run() \n",
    "mlflow.log_param('max_depth', max_depth) \n",
    "mlflow.end_run()\n",
    "```\n",
    "\n",
    "### Usando MLFlow con un ejemplo de Iris-Dataset\n",
    "\n",
    "Vamos a emplear MLFlow para entrenar un modelo utilizando el conjunto de datos Iris. El modelo que utilizaremos será Random Forest de Scikit-Learn. Realizaremos una búsqueda \n",
    "de hiperparámetros mediante una búsqueda en cuadrícula y registraremos los mejores parámetros encontrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57f97ec35d3b9c42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T18:10:12.508818Z",
     "start_time": "2024-04-20T18:10:12.284064Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29c9f7d6a511f59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T18:10:13.025986Z",
     "start_time": "2024-04-20T18:10:13.022567Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('http://localhost:5001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54e00756039b40b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T18:10:13.649789Z",
     "start_time": "2024-04-20T18:10:13.617786Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "experiment_name = \"experiment_iris\"\n",
    "\n",
    "if not mlflow.get_experiment_by_name(experiment_name):\n",
    "    mlflow.create_experiment(name=experiment_name) \n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18af875707a1330c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T18:10:20.283909Z",
     "start_time": "2024-04-20T18:10:20.276997Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Cargo los datos\n",
    "data = load_iris()\n",
    "\n",
    "# Separamos entre evaluación y testeo\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['data'], data['target'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c893fd0ac347cb6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T18:10:22.405502Z",
     "start_time": "2024-04-20T18:10:22.401967Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Armamos el modelo base\n",
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "884f3fe2547dbf8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T18:10:44.641060Z",
     "start_time": "2024-04-20T18:10:23.209655Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los mejores parámetros son: {'max_depth': 8, 'max_features': 3, 'min_samples_leaf': 3, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "# Definimos los hiperparámetros para la búsqueda\n",
    "grid = {\n",
    "    'max_depth':[6,8,10], \n",
    "    'min_samples_split':[2,3,4,5],\n",
    "    'min_samples_leaf':[2,3,4,5],\n",
    "    'max_features': [2,3]\n",
    "    }\n",
    "\n",
    "# Hacemos la búsqueda\n",
    "iris_grid = GridSearchCV(model, grid, cv=5) \n",
    "iris_grid_results = iris_grid.fit(X_train, y_train)\n",
    "\n",
    "print(f'Los mejores parámetros son: {iris_grid_results.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e00d2709ae57e1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Con el mejor modelo, registramos toda la información:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e551cb588b50ffac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T18:10:47.546574Z",
     "start_time": "2024-04-20T18:10:44.642365Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(experiment_id = experiment.experiment_id):\n",
    "    # Se registran los mejores hiperparámetros\n",
    "    mlflow.log_params(iris_grid_results.best_params_)\n",
    "    \n",
    "    # Se obtiene las predicciones del dataset de evaluación\n",
    "    y_pred = iris_grid_results.predict(X_test)\n",
    "    \n",
    "    # Se calculan las métricas\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    \n",
    "    # Y las enviamos a MLFlow\n",
    "    metrics ={\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision, \n",
    "        'recall': recall \n",
    "        }\n",
    "    mlflow.log_metrics(metrics)\n",
    "    \n",
    "    # Como artefactos, obtenemos las gráficas de la curva ROC y la matriz de confusion\n",
    "    matrix_plot = plot_confusion_matrix(y_test, y_pred, save_path=None)\n",
    "    roc_plots = plot_roc_curve(y_test, y_pred, save_path=None)\n",
    "    \n",
    "    mlflow.log_figure(matrix_plot, artifact_file=\"matrix_plot.png\")\n",
    "    mlflow.log_figure(roc_plots[0], artifact_file=\"roc_curve_1_plot.png\")\n",
    "    mlflow.log_figure(roc_plots[1], artifact_file=\"roc_curve_2_plot.png\")\n",
    "    mlflow.log_figure(roc_plots[2], artifact_file=\"roc_curve_3_plot.png\")\n",
    "    \n",
    "    # Registramos el modelo y los datos de entrenamiento\n",
    "    mlflow.sklearn.log_model(iris_grid_results, 'iris_rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe75edcc127c8fe",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Registrar un modelo\n",
    "\n",
    "Una vez que hemos subido un modelo a MLFlow, ponerlo en producción es un proceso sencillo. Para ello, nos dirigimos a la pestaña *Artifacts* del modelo que deseamos implementar. Allí, hacemos click en el botón *Register Model*,, lo que registrará el modelo en el sistema.\n",
    "\n",
    "Ahora, para obtener predicciones, tenemos dos opciones:\n",
    "\n",
    "1. Leer el artefacto del servidor de MLFlow y lo usamos para hacer predicciones.\n",
    "2. Publicar el artefacto como un endpoint.\n",
    "\n",
    "#### Hacer predicciones de un modelo de MLFlow\n",
    "\n",
    "Para obtener predicciones, vamos al apartado de *Artifacts* donde MLFlow indica cómo podemos obtener predicciones del modelo, ya sea utilizando Spark o Python. \n",
    "Copiamos ese código y lo ejecutamos, proporcionando los datos que deseamos predecir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b444fde386b54a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T18:12:56.398222Z",
     "start_time": "2024-04-20T18:12:56.218958Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logged_model = 'runs:/402e88bd4bf14fca9e40f1cb9ad87212/iris_rf'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "loaded_model.predict(pd.DataFrame(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc29c47dfca49e4d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "El segundo formato permite desplegar un modelo mediante una REST API. Esto queda por fuera del hands-on, pero se puede consultar más [acá](https://mlflow.org/docs/latest/deployment/index.html).\n",
    "\n",
    "Si queres ver más aplicaciones, podes ver la notebook del repositorio del proyecto final, el [ejemplo de aplicación](https://github.com/facundolucianna/amq2-service-ml/tree/example_implementation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82eaf80b9efa600",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
